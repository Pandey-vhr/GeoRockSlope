{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb1bb08-0f5f-4ee5-ad60-61e6dfe2cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 ACO Generation 1\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 2\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 3\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 4\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 5\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 6\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 7\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 8\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 9\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 10\n",
      "Top R² so far: 0.904299 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🏁 Final Training with ACO Best Parameters\n",
      "\n",
      "📊 Final ACO-ANN Evaluation for FoS\n",
      "Best Hyperparameters: (58, 123, 98, 0.00643)\n",
      "✅ R² (Train): 0.997709\n",
      "✅ R² (Test):  0.906126\n",
      "📉 RMSE (Train): 0.055191\n",
      "📉 RMSE (Test):  0.389779\n",
      "📉 MAE (Train): 0.039630\n",
      "📉 MAE (Test):  0.255074\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# === Force CPU execution\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# === Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "# === ANN definition\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, h1, h2, h3):\n",
    "        super(ANN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, h1), nn.ReLU(),\n",
    "            nn.Linear(h1, h2), nn.ReLU(),\n",
    "            nn.Linear(h2, h3), nn.ReLU(),\n",
    "            nn.Linear(h3, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# === Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\vishn\\OneDrive\\Documents\\Machine Learning\\Vishnu_phd.csv\")\n",
    "X = df.drop(columns=[\"FoS\", \"SeismicFoS\"]).values\n",
    "y = df[\"FoS\"].values\n",
    "\n",
    "# === Train-test split & scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# === Evaluation function\n",
    "def evaluate_model(h1, h2, h3, lr):\n",
    "    set_seed(42)\n",
    "    model = ANN(X_train.shape[1], h1, h2, h3).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test_tensor).cpu().numpy()\n",
    "    return r2_score(y_test, y_pred_test)\n",
    "\n",
    "# === ACO Initialization\n",
    "def value(i): return 16 + i\n",
    "NUM_ANTS = 10\n",
    "NUM_ITER = 10\n",
    "pheromone = np.ones((113, 113, 113))\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "# === ACO Loop\n",
    "for gen in range(NUM_ITER):\n",
    "    print(f\"\\n🔄 ACO Generation {gen+1}\")\n",
    "    for _ in range(NUM_ANTS):\n",
    "        h1i = np.random.choice(113, p=pheromone.sum((1,2)) / pheromone.sum())\n",
    "        h2i = np.random.choice(113, p=pheromone[h1i].sum(1) / pheromone[h1i].sum())\n",
    "        h3i = np.random.choice(113, p=pheromone[h1i,h2i] / pheromone[h1i,h2i].sum())\n",
    "        lr = round(random.uniform(0.0001, 0.01), 5)\n",
    "\n",
    "        h1, h2, h3 = value(h1i), value(h2i), value(h3i)\n",
    "        score = evaluate_model(h1, h2, h3, lr)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = (h1, h2, h3, lr)\n",
    "\n",
    "        pheromone[h1i, h2i, h3i] += score\n",
    "\n",
    "    print(f\"Top R² so far: {best_score:.6f} | Params: {best_params}\")\n",
    "\n",
    "# === Final model training with best ACO params\n",
    "print(\"\\n🏁 Final Training with ACO Best Parameters\")\n",
    "final_model = ANN(X_train.shape[1], *best_params[:3]).to(device)\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=best_params[3])\n",
    "criterion = nn.MSELoss()\n",
    "set_seed(42)\n",
    "for epoch in range(100):\n",
    "    final_model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = final_model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# === Final evaluation\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = final_model(X_train_tensor).cpu().numpy()\n",
    "    y_test_pred = final_model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# === Print final results\n",
    "print(f\"\\n📊 Final ACO-ANN Evaluation for FoS\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"✅ R² (Train): {r2_train:.6f}\")\n",
    "print(f\"✅ R² (Test):  {r2_test:.6f}\")\n",
    "print(f\"📉 RMSE (Train): {rmse_train:.6f}\")\n",
    "print(f\"📉 RMSE (Test):  {rmse:.6f}\")\n",
    "print(f\"📉 MAE (Train): {mae_train:.6f}\")\n",
    "print(f\"📉 MAE (Test):  {mae:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b81e924-9ee9-4549-8f9e-38fc311c44f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 ACO Generation 1\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 2\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 3\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 4\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 5\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 6\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 7\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 8\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 9\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🔄 ACO Generation 10\n",
      "Top R² so far: 0.787456 | Params: (58, 123, 98, 0.00643)\n",
      "\n",
      "🏁 Final Training with ACO Best Parameters\n",
      "\n",
      "📊 Final ACO-ANN Evaluation for SeismicFoS\n",
      "Best Hyperparameters: (58, 123, 98, 0.00643)\n",
      "✅ R² (Train): 0.960125\n",
      "✅ R² (Test):  0.796276\n",
      "📉 RMSE (Train): 0.174396\n",
      "📉 RMSE (Test):  0.423792\n",
      "📉 MAE (Train): 0.104484\n",
      "📉 MAE (Test):  0.273871\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# === Force CPU execution\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# === Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "# === ANN definition\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, h1, h2, h3):\n",
    "        super(ANN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, h1), nn.ReLU(),\n",
    "            nn.Linear(h1, h2), nn.ReLU(),\n",
    "            nn.Linear(h2, h3), nn.ReLU(),\n",
    "            nn.Linear(h3, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# === Load data for SeismicFoS\n",
    "df = pd.read_csv(r\"C:\\Users\\vishn\\OneDrive\\Documents\\Machine Learning\\Vishnu_phd.csv\")\n",
    "X = df.drop(columns=[\"FoS\", \"SeismicFoS\"]).values\n",
    "y = df[\"SeismicFoS\"].values  # ✅ Target: SeismicFoS\n",
    "\n",
    "# === Train-test split & scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# === Model evaluation function\n",
    "def evaluate_model(h1, h2, h3, lr):\n",
    "    set_seed(42)\n",
    "    model = ANN(X_train.shape[1], h1, h2, h3).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test_tensor).cpu().numpy()\n",
    "    return r2_score(y_test, y_pred_test)\n",
    "\n",
    "# === ACO setup\n",
    "def value(i): return 16 + i\n",
    "NUM_ANTS = 10\n",
    "NUM_ITER = 10\n",
    "pheromone = np.ones((113, 113, 113))  # For h1, h2, h3 options\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "# === ACO optimization loop\n",
    "for gen in range(NUM_ITER):\n",
    "    print(f\"\\n🔄 ACO Generation {gen+1}\")\n",
    "    for _ in range(NUM_ANTS):\n",
    "        h1i = np.random.choice(113, p=pheromone.sum((1,2)) / pheromone.sum())\n",
    "        h2i = np.random.choice(113, p=pheromone[h1i].sum(1) / pheromone[h1i].sum())\n",
    "        h3i = np.random.choice(113, p=pheromone[h1i,h2i] / pheromone[h1i,h2i].sum())\n",
    "        lr = round(random.uniform(0.0001, 0.01), 5)\n",
    "\n",
    "        h1, h2, h3 = value(h1i), value(h2i), value(h3i)\n",
    "        score = evaluate_model(h1, h2, h3, lr)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = (h1, h2, h3, lr)\n",
    "\n",
    "        pheromone[h1i, h2i, h3i] += score\n",
    "\n",
    "    print(f\"Top R² so far: {best_score:.6f} | Params: {best_params}\")\n",
    "\n",
    "# === Final training with best parameters\n",
    "print(\"\\n🏁 Final Training with ACO Best Parameters\")\n",
    "final_model = ANN(X_train.shape[1], *best_params[:3]).to(device)\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=best_params[3])\n",
    "criterion = nn.MSELoss()\n",
    "set_seed(42)\n",
    "\n",
    "for epoch in range(100):\n",
    "    final_model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = final_model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# === Final evaluation\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = final_model(X_train_tensor).cpu().numpy()\n",
    "    y_test_pred = final_model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# === Print final results\n",
    "print(f\"\\n📊 Final ACO-ANN Evaluation for SeismicFoS\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"✅ R² (Train): {r2_train:.6f}\")\n",
    "print(f\"✅ R² (Test):  {r2_test:.6f}\")\n",
    "print(f\"📉 RMSE (Train): {rmse_train:.6f}\")\n",
    "print(f\"📉 RMSE (Test):  {rmse_test:.6f}\")\n",
    "print(f\"📉 MAE (Train): {mae_train:.6f}\")\n",
    "print(f\"📉 MAE (Test):  {mae_test:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
